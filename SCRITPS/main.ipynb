{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eabc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install \"tensorflow[and-cuda]==2.19.*\" -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09546e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade --no-cache-dir --force-reinstall \\\n",
    "# \"numpy==1.26.4\" \\\n",
    "# \"scipy==1.12.0\" \\\n",
    "# \"scikit-learn==1.6.*\" \\\n",
    "# \"umap-learn>=0.5.9.post2\" \\\n",
    "# \"tensorflow==2.19.*\" \"tf-keras==2.19.*\" \"tensorflow-text==2.19.*\" \\\n",
    "# \"tensorflow-decision-forests==1.12.*\" \\\n",
    "# \"gensim>=4.3,<4.4\" \\\n",
    "# \"kagglehub[hf-datasets]\"\\\n",
    "# \"matplotlib\"\\\n",
    "# \"nltk\"\\\n",
    "# \"seaborn\"\\\n",
    "# \"datasets\"\\\n",
    "# \"transformers\"\\\n",
    "# \"torch\" \"accelerate\"\\\n",
    "# -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18c3c450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visible GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "OK, matmul is ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1759691149.668495  122700 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5518 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:64:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf, torch\n",
    "\n",
    "print(\"Visible GPUs:\", tf.config.list_physical_devices(\"GPU\"))\n",
    "\n",
    "for g in tf.config.list_physical_devices(\"GPU\"):\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(g, True)\n",
    "    except Exception as e:\n",
    "        print(\"Could not activate memory_growth:\", e)\n",
    "\n",
    "x = tf.random.normal((4096, 4096))\n",
    "y = tf.linalg.matmul(x, x)\n",
    "print(\"OK, matmul is ready.\")\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61c4a7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eubgo/anaconda3/envs/FIFA-WC-sentiment-analysis/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy: 1.26.4\n",
      "SciPy: 1.12.0\n",
      "Gensim: 4.3.3\n",
      "scikit-learn: 1.6.1\n",
      "TensorFlow: 2.19.0\n",
      "tensorflow-text: 2.19.0\n",
      "Has la.triu? True\n"
     ]
    }
   ],
   "source": [
    "import numpy, scipy, gensim, sklearn\n",
    "import tensorflow as tf, tensorflow_text as text\n",
    "import umap\n",
    "\n",
    "print(\"NumPy:\", numpy.__version__)\n",
    "print(\"SciPy:\", scipy.__version__)\n",
    "print(\"Gensim:\", gensim.__version__)\n",
    "print(\"scikit-learn:\", sklearn.__version__)\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"tensorflow-text:\", text.__version__)\n",
    "import scipy.linalg as la\n",
    "\n",
    "print(\"Has la.triu?\", hasattr(la, \"triu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cebfe0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 15:38:45.009956: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-05 15:38:45.322511: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759700325.458694  138278 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1759700325.496704  138278 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1759700325.756557  138278 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759700325.756606  138278 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759700325.756608  138278 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759700325.756609  138278 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-10-05 15:38:45.784563: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/eubgo/anaconda3/envs/FIFA-WC-sentiment-analysis/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 0) IMPORTS + CONFIG\n",
    "# =========================\n",
    "import os, re, json, warnings, random, math, sys\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Classic ML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Keras / TF\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "\n",
    "# DL\n",
    "import gensim.downloader as api\n",
    "\n",
    "# HF / Transformers\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from datasets import Dataset\n",
    "\n",
    "# KaggleHub\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b0b1147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- FLAGS  -----\n",
    "RUN_TFIDF_MODELS = True\n",
    "\n",
    "RUN_CNN_TWITTER_SE = True\n",
    "RUN_LSTM_BIATTN = True\n",
    "\n",
    "RUN_ROBERTA_FEATURES = True\n",
    "RUN_ROBERTA_FINETUNE = True\n",
    "\n",
    "RUN_ENSEMBLE_MODELS = True\n",
    "\n",
    "MAKE_FIGURES = True\n",
    "SAVE_PER_EXAMPLE_CSV = True\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5a166a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff2132a4650>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n",
    "tf.random.set_seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cc19a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR = Path(\"artifacts\")\n",
    "OUTDIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "CACHE_DIR = OUTDIR / \"cache_roberta_feats\"\n",
    "CACHE_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "FIGDIR = OUTDIR / \"figures\"\n",
    "TABDIR = OUTDIR / \"tables\"\n",
    "LOGDIR = OUTDIR / \"logs\"\n",
    "for d in (FIGDIR, TABDIR, LOGDIR):\n",
    "    d.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09e7a990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Torch device: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"[INFO] Torch device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a91c7e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 1) UTILS\n",
    "# =========================\n",
    "def preprocess(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"@\\w+\", \"USR\", text)\n",
    "    text = re.sub(r\"(https?://\\S+|www\\.\\S+)\", \"URL\", text)\n",
    "    text = re.sub(r\"#(\\w+)\", r\"hash_\\1\", text)\n",
    "\n",
    "    emoticons = r\":\\)|:-\\)|:\\(|:-\\(|:d|:-d|:p|:-p|;-\\)|;\\)|xd|xD|:\\'\\(|<3|♥\"\n",
    "    emojis = r\"🤩|😍|😊|😃|😁|😂|🤣|😅|😢|😭|😡|😠|😤|😞|😔|😐|😑|😕|😒|🙃|😉|😎|🥳|🥲|🤔|🙄|😬|🥺|😳|😇|👍|🙏|🔥|💪|👎|💀|🤮|🤯|🤬\"\n",
    "\n",
    "    allowed = rf\"[a-z0-9_#!?/\\s:)(\\-]+\"\n",
    "    parts = re.findall(\n",
    "        rf\"(?:{allowed}|{emoticons}|{emojis})\", text, flags=re.IGNORECASE\n",
    "    )\n",
    "    text = \" \".join(parts)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2603a5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset() -> pd.DataFrame:\n",
    "    try:\n",
    "        file_path = \"fifa_world_cup_2022_tweets.csv\"\n",
    "        hf_dataset = kagglehub.dataset_load(\n",
    "            KaggleDatasetAdapter.HUGGING_FACE,\n",
    "            \"tirendazacademy/fifa-world-cup-2022-tweets\",\n",
    "            file_path,\n",
    "        )\n",
    "        return hf_dataset.to_pandas()\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] No pude descargar dataset:\", e)\n",
    "        if os.path.exists(\"data/fifa_world_cup_2022_tweets_local.csv\"):\n",
    "            return pd.read_csv(\"data/fifa_world_cup_2022_tweets_local.csv\")\n",
    "        else:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b60aac08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_result(\n",
    "    container: list,\n",
    "    model_name: str,\n",
    "    report_dict=None,\n",
    "    acc=None,\n",
    "    prec=None,\n",
    "    rec=None,\n",
    "    f1=None,\n",
    "):\n",
    "    if any(r[\"Model\"] == model_name for r in container):\n",
    "        return\n",
    "    if report_dict:\n",
    "        acc = report_dict.get(\"accuracy\", acc)\n",
    "        prec = report_dict.get(\"precision\", prec)\n",
    "        rec = report_dict.get(\"recall\", rec)\n",
    "        f1 = report_dict.get(\"f1\", f1)\n",
    "    container.append(\n",
    "        {\n",
    "            \"Model\": model_name,\n",
    "            \"Accuracy\": round(acc, 4) if acc is not None else None,\n",
    "            \"Precision\": round(prec, 4) if prec is not None else None,\n",
    "            \"Recall\": round(rec, 4) if rec is not None else None,\n",
    "            \"F1\": round(f1, 4) if f1 is not None else None,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b02c8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_and_add(container, name, y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"macro\")\n",
    "    add_result(container, name, acc=acc, prec=prec, rec=rec, f1=f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fd12104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading dataset...\n",
      "[INFO] Original shape: (22524, 6)\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 2) DATA & SPLIT\n",
    "# =========================\n",
    "print(\"[INFO] Loading dataset...\")\n",
    "df = load_dataset()\n",
    "print(\"[INFO] Original shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ce0491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "positive    8489\n",
       "neutral     8251\n",
       "negative    5784\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce5178bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=\"Tweet\", inplace=True)\n",
    "df = df[df[\"Tweet\"].notnull() & (df[\"Tweet\"].str.strip() != \"\")]\n",
    "df[\"clean_tweet\"] = df[\"Tweet\"].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ec3d1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clf = df[[\"clean_tweet\", \"Sentiment\"]].copy()\n",
    "X = df_clf[\"clean_tweet\"]\n",
    "y = df_clf[\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6378e14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Train/Test: (17888,) (4472,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "print(\"[INFO] Train/Test:\", X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0dd695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FIG] class_distribution_split.png\n"
     ]
    }
   ],
   "source": [
    "dist_split = pd.DataFrame(\n",
    "    {\n",
    "        \"split\": [\"train\"] * len(y_train) + [\"test\"] * len(y_test),\n",
    "        \"label\": pd.concat([y_train, y_test]).values,\n",
    "    }\n",
    ")\n",
    "plt.figure(figsize=(6.2, 4.2))\n",
    "sns.countplot(\n",
    "    data=dist_split, x=\"label\", hue=\"split\", order=sorted(df[\"Sentiment\"].unique())\n",
    ")\n",
    "plt.title(\"Class Distribution by Split\")\n",
    "out = FIGDIR / \"class_distribution_split.png\"\n",
    "plt.savefig(out, dpi=160)\n",
    "plt.close()\n",
    "print(f\"[FIG] {out.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c35705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Classes: ['negative', 'neutral', 'positive']\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.transform(y_test)\n",
    "num_classes = len(le.classes_)\n",
    "print(\"[INFO] Classes:\", list(le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8229244",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_enc = np.unique(y_train_enc)\n",
    "weights = compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=classes_enc, y=y_train_enc\n",
    ")\n",
    "class_weight_keras = {int(c): float(w) for c, w in zip(classes_enc, weights)}\n",
    "\n",
    "if \"neutral\" in le.classes_:\n",
    "    neutral_id = int(np.where(le.classes_ == \"neutral\")[0][0])\n",
    "    class_weight_keras_tuned = class_weight_keras.copy()\n",
    "    class_weight_keras_tuned[neutral_id] *= 1.15\n",
    "else:\n",
    "    class_weight_keras_tuned = class_weight_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "afd0df38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================\n",
    "# 3) TF-IDF + TRADITIONAL ML MODELS\n",
    "# =================================\n",
    "results_all = []\n",
    "vectorizer = None\n",
    "X_train_tfidf = None\n",
    "X_test_tfidf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ca3a42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TF-IDF] Training traditional ML models...\n",
      "[RESULT] Logistic Regression (TF-IDF): 0.7068425760286225\n",
      "[RESULT] LinearSVC (TF-IDF): 0.6985688729874776\n",
      "[RESULT] RandomForest (TF-IDF): 0.6773255813953488\n"
     ]
    }
   ],
   "source": [
    "if RUN_TFIDF_MODELS:\n",
    "    print(\"\\n[TF-IDF] Training traditional ML models...\")\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_features=50_000, ngram_range=(1, 3), min_df=2, stop_words=\"english\"\n",
    "    )\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "    # Logistic Regression\n",
    "    log_reg = LogisticRegression(\n",
    "        max_iter=2000, random_state=RANDOM_STATE, class_weight=\"balanced\"\n",
    "    )\n",
    "    log_reg.fit(X_train_tfidf, y_train)\n",
    "    y_pred = log_reg.predict(X_test_tfidf)\n",
    "    y_proba_lr = log_reg.predict_proba(X_test_tfidf)\n",
    "    eval_and_add(results_all, \"Logistic Regression (TF-IDF)\", y_test, y_pred)\n",
    "    print(\n",
    "        f\"[RESULT] Logistic Regression (TF-IDF): {log_reg.score(X_test_tfidf, y_test)}\"\n",
    "    )\n",
    "\n",
    "    # Linear SVC\n",
    "    svm_clf = LinearSVC(random_state=RANDOM_STATE)\n",
    "    svm_clf.fit(X_train_tfidf, y_train)\n",
    "    y_pred = svm_clf.predict(X_test_tfidf)\n",
    "    eval_and_add(results_all, \"LinearSVC (TF-IDF)\", y_test, y_pred)\n",
    "    print(f\"[RESULT] LinearSVC (TF-IDF): {svm_clf.score(X_test_tfidf, y_test)}\")\n",
    "\n",
    "    # Random Forest\n",
    "    rf_clf = RandomForestClassifier(\n",
    "        n_estimators=400,\n",
    "        max_depth=None,\n",
    "        min_samples_split=2,\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE,\n",
    "        class_weight=\"balanced_subsample\",\n",
    "    )\n",
    "    rf_clf.fit(X_train_tfidf, y_train)\n",
    "    y_pred = rf_clf.predict(X_test_tfidf)\n",
    "    y_proba_rf = rf_clf.predict_proba(X_test_tfidf)\n",
    "    eval_and_add(results_all, \"RandomForest (TF-IDF)\", y_test, y_pred)\n",
    "    print(f\"[RESULT] RandomForest (TF-IDF): {rf_clf.score(X_test_tfidf, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12fc351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# 4) DL – Tokenizer + Twitter embeddings + CNN SE+Attn\n",
    "# ========================================================\n",
    "tok = None\n",
    "Xtr_pad = None\n",
    "Xte_pad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407514ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_embedding_matrix(kv, tokenizer, max_vocab):\n",
    "    dim = kv.vector_size\n",
    "    mat = np.random.normal(0, 0.6, size=(max_vocab, dim)).astype(\"float32\")\n",
    "    mat[0] = 0.0\n",
    "\n",
    "    known = [\n",
    "        kv[w]\n",
    "        for w, idx in tokenizer.word_index.items()\n",
    "        if idx < max_vocab and (w in kv)\n",
    "    ]\n",
    "    mean_vec = np.mean(known, axis=0) if len(known) else np.zeros(dim, dtype=\"float32\")\n",
    "\n",
    "    for w, idx in tokenizer.word_index.items():\n",
    "        if idx >= max_vocab:\n",
    "            continue\n",
    "        if w in kv:\n",
    "            mat[idx] = kv[w]\n",
    "    oov_idx = tokenizer.word_index.get(\"<OOV>\")\n",
    "    if oov_idx is not None and oov_idx < max_vocab:\n",
    "        mat[oov_idx] = mean_vec\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f1e14389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def se_block(x, r=8):\n",
    "    ch = x.shape[-1]\n",
    "    s = layers.GlobalAveragePooling1D()(x)\n",
    "    s = layers.Dense(ch // r, activation=\"relu\")(s)\n",
    "    s = layers.Dense(ch, activation=\"sigmoid\")(s)\n",
    "    s = layers.Reshape((1, ch))(s)\n",
    "    return layers.Multiply()([x, s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1e94698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_pool(h):\n",
    "    maxp = layers.GlobalMaxPooling1D()(h)\n",
    "    avgp = layers.GlobalAveragePooling1D()(h)\n",
    "    a = layers.Dense(64, activation=\"tanh\")(h)\n",
    "    a = layers.Dense(1, use_bias=False)(a)\n",
    "    a = layers.Lambda(lambda x: tf.nn.softmax(x, axis=1))(a)\n",
    "    att = layers.Multiply()([h, a])\n",
    "    att = layers.Lambda(lambda x: tf.reduce_sum(x, axis=1))(att)\n",
    "    return layers.Concatenate()([maxp, avgp, att])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82f29709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lstm_biattn(\n",
    "    vocab_size,\n",
    "    emb_matrix,\n",
    "    max_len,\n",
    "    num_classes,\n",
    "    trainable=False,\n",
    "    lstm1_units=96,\n",
    "    lstm2_units=64,\n",
    "    dropout_rate=0.4,\n",
    "    use_recurrent_dropout=True,\n",
    "):\n",
    "    from tensorflow.keras import layers, models, regularizers\n",
    "    import tensorflow as tf\n",
    "\n",
    "    def attention_pool(h):\n",
    "        maxp = layers.GlobalMaxPooling1D()(h)\n",
    "        avgp = layers.GlobalAveragePooling1D()(h)\n",
    "        a = layers.Dense(64, activation=\"tanh\")(h)\n",
    "        a = layers.Dense(1, use_bias=False)(a)\n",
    "        a = layers.Lambda(lambda x: tf.nn.softmax(x, axis=1))(a)\n",
    "        att = layers.Multiply()([h, a])\n",
    "        att = layers.Lambda(lambda x: tf.reduce_sum(x, axis=1))(att)\n",
    "        return layers.Concatenate()([maxp, avgp, att])\n",
    "\n",
    "    emb_dim = emb_matrix.shape[1]\n",
    "    inp = layers.Input(shape=(max_len,), name=\"input_ids\")\n",
    "    x = layers.Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=emb_dim,\n",
    "        weights=[emb_matrix],\n",
    "        trainable=trainable,\n",
    "        mask_zero=True,\n",
    "        name=\"embedding\",\n",
    "    )(inp)\n",
    "\n",
    "    x = layers.SpatialDropout1D(0.2)(x)\n",
    "\n",
    "    rd1 = 0.2 if use_recurrent_dropout else 0.0\n",
    "    rd2 = 0.2 if use_recurrent_dropout else 0.0\n",
    "\n",
    "    x = layers.Bidirectional(\n",
    "        layers.LSTM(\n",
    "            lstm1_units, return_sequences=True, dropout=0.2, recurrent_dropout=rd1\n",
    "        )\n",
    "    )(x)\n",
    "    x = layers.Bidirectional(\n",
    "        layers.LSTM(\n",
    "            lstm2_units, return_sequences=True, dropout=0.2, recurrent_dropout=rd2\n",
    "        )\n",
    "    )(x)\n",
    "\n",
    "    h = attention_pool(x)\n",
    "    h = layers.Dropout(dropout_rate)(h)\n",
    "    h = layers.Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(1e-4))(\n",
    "        h\n",
    "    )\n",
    "    h = layers.Dropout(dropout_rate)(h)\n",
    "\n",
    "    out = layers.Dense(num_classes, activation=\"softmax\")(h)\n",
    "\n",
    "    model = models.Model(inp, out, name=\"BiLSTM_Attn\")\n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a2a01075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[BiLSTM+Attn] Preparing embeddings + model...\n",
      "Epoch 1/8\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 71ms/step - accuracy: 0.5810 - loss: 0.8919 - val_accuracy: 0.6875 - val_loss: 0.7173 - learning_rate: 0.0010\n",
      "Epoch 2/8\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - accuracy: 0.6851 - loss: 0.7198 - val_accuracy: 0.7300 - val_loss: 0.6423 - learning_rate: 0.0010\n",
      "Epoch 3/8\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 67ms/step - accuracy: 0.7081 - loss: 0.6699 - val_accuracy: 0.7485 - val_loss: 0.6154 - learning_rate: 0.0010\n",
      "Epoch 4/8\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 68ms/step - accuracy: 0.7307 - loss: 0.6324 - val_accuracy: 0.7513 - val_loss: 0.6050 - learning_rate: 0.0010\n",
      "Epoch 5/8\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 66ms/step - accuracy: 0.7444 - loss: 0.6036 - val_accuracy: 0.7602 - val_loss: 0.5834 - learning_rate: 0.0010\n",
      "Epoch 6/8\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 64ms/step - accuracy: 0.7565 - loss: 0.5759 - val_accuracy: 0.7697 - val_loss: 0.5739 - learning_rate: 0.0010\n",
      "Epoch 7/8\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 66ms/step - accuracy: 0.7615 - loss: 0.5575 - val_accuracy: 0.7613 - val_loss: 0.5750 - learning_rate: 0.0010\n",
      "Epoch 8/8\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 67ms/step - accuracy: 0.7775 - loss: 0.5313 - val_accuracy: 0.7630 - val_loss: 0.5671 - learning_rate: 0.0010\n",
      "Epoch 1/8\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 65ms/step - accuracy: 0.7932 - loss: 0.4918 - val_accuracy: 0.7691 - val_loss: 0.5672 - learning_rate: 1.0000e-04\n",
      "Epoch 2/8\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7956 - loss: 0.4814\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 60ms/step - accuracy: 0.7979 - loss: 0.4697 - val_accuracy: 0.7647 - val_loss: 0.5706 - learning_rate: 1.0000e-04\n",
      "Epoch 3/8\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 61ms/step - accuracy: 0.8048 - loss: 0.4561 - val_accuracy: 0.7686 - val_loss: 0.5731 - learning_rate: 5.0000e-05\n",
      "Epoch 1/6\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 64ms/step - accuracy: 0.7988 - loss: 0.4994 - val_accuracy: 0.7714 - val_loss: 0.5623\n",
      "Epoch 2/6\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 59ms/step - accuracy: 0.8025 - loss: 0.4945 - val_accuracy: 0.7725 - val_loss: 0.5629\n",
      "Epoch 3/6\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 60ms/step - accuracy: 0.8012 - loss: 0.4956 - val_accuracy: 0.7725 - val_loss: 0.5608\n",
      "Epoch 4/6\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 59ms/step - accuracy: 0.8045 - loss: 0.4932 - val_accuracy: 0.7686 - val_loss: 0.5641\n",
      "Epoch 5/6\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 57ms/step - accuracy: 0.8054 - loss: 0.4864 - val_accuracy: 0.7708 - val_loss: 0.5639\n",
      "Epoch 6/6\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 58ms/step - accuracy: 0.8079 - loss: 0.4834 - val_accuracy: 0.7719 - val_loss: 0.5631\n",
      "[RESULT] BiLSTM+Attention (GloVe-Twitter): 0.7670\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "if RUN_LSTM_BIATTN:\n",
    "    cb_lstm_stage12 = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=3, restore_best_weights=True\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\", factor=0.5, patience=2, min_lr=1e-5, verbose=1\n",
    "        ),\n",
    "    ]\n",
    "    cb_lstm_stage3 = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=3, restore_best_weights=True\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    print(\"\\n[BiLSTM+Attn] Preparing embeddings + model...\")\n",
    "\n",
    "    MAX_VOCAB = 50_000\n",
    "    MAX_LEN = 180\n",
    "\n",
    "    if tok is None or Xtr_pad is None or Xte_pad is None:\n",
    "        print(\n",
    "            \"[BiLSTM+Attn] Didn't found tokenizer/padding. Creating them...\"\n",
    "        )\n",
    "        X_train_dl = X_train.str.replace(r\"\\bhash_\", \"\", regex=True)\n",
    "        X_test_dl = X_test.str.replace(r\"\\bhash_\", \"\", regex=True)\n",
    "\n",
    "        tok = Tokenizer(num_words=MAX_VOCAB, oov_token=\"<OOV>\")\n",
    "        tok.fit_on_texts(X_train_dl)\n",
    "        Xtr_seq = tok.texts_to_sequences(X_train_dl)\n",
    "        Xte_seq = tok.texts_to_sequences(X_test_dl)\n",
    "        Xtr_pad = pad_sequences(\n",
    "            Xtr_seq, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\"\n",
    "        )\n",
    "        Xte_pad = pad_sequences(\n",
    "            Xte_seq, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\"\n",
    "        )\n",
    "    VOCAB_SIZE = min(MAX_VOCAB, len(tok.word_index) + 1)\n",
    "\n",
    "    # --- GloVe-Twitter Embeddings ---\n",
    "    if \"emb_twitter\" not in locals():\n",
    "        try:\n",
    "            glove_tw = api.load(\"glove-twitter-200\")\n",
    "        except Exception as e:\n",
    "            print(\"[WARN] Could not download GloVe:\", e)\n",
    "            if os.path.exists(\"vectors/glove-twitter-200.kv\"):\n",
    "                glove_tw = KeyedVectors.load(\"vectors/glove-twitter-200.kv\")\n",
    "            else:\n",
    "                raise e\n",
    "        emb_twitter = build_embedding_matrix(glove_tw, tok, MAX_VOCAB)\n",
    "        emb_twitter = emb_twitter[:VOCAB_SIZE, :]\n",
    "\n",
    "    emb_lstm = emb_twitter.copy()\n",
    "    if emb_lstm.shape[0] > 0 and np.any(emb_lstm[0] != 0.0):\n",
    "        emb_lstm[0] = 0.0\n",
    "\n",
    "    # --- LSTM Model ---\n",
    "    lstm_glove = make_lstm_biattn(\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        emb_matrix=emb_lstm,\n",
    "        max_len=MAX_LEN,\n",
    "        num_classes=num_classes,\n",
    "        trainable=False,\n",
    "        lstm1_units=96,\n",
    "        lstm2_units=64,\n",
    "        dropout_rate=0.4,\n",
    "        use_recurrent_dropout=False,\n",
    "    )\n",
    "\n",
    "    # ===== Stage 1 =====\n",
    "    history_lstm_1 = lstm_glove.fit(\n",
    "        Xtr_pad,\n",
    "        y_train_enc,\n",
    "        validation_split=0.1,\n",
    "        epochs=8,\n",
    "        batch_size=64,\n",
    "        callbacks=cb_lstm_stage12,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    # ===== Stage 2: unfreeze embedding + class_weight =====\n",
    "    lstm_glove.get_layer(\"embedding\").trainable = True\n",
    "    lstm_glove.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        optimizer=tf.keras.optimizers.Adam(1e-4, clipnorm=1.0),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    history_lstm_2 = lstm_glove.fit(\n",
    "        Xtr_pad,\n",
    "        y_train_enc,\n",
    "        validation_split=0.1,\n",
    "        epochs=8,\n",
    "        batch_size=64,\n",
    "        class_weight=class_weight_keras,\n",
    "        callbacks=cb_lstm_stage12,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    # ===== Stage 3: CosineDecayRestarts  =====\n",
    "    batch_size_stage3 = 64\n",
    "    steps_per_epoch = int(\n",
    "        np.ceil(len(Xtr_pad) * 0.9 / batch_size_stage3)\n",
    "    )\n",
    "\n",
    "    sched = tf.keras.optimizers.schedules.CosineDecayRestarts(\n",
    "        initial_learning_rate=5e-5,\n",
    "        first_decay_steps=steps_per_epoch,\n",
    "        t_mul=2.0,\n",
    "        m_mul=0.9,\n",
    "        alpha=1e-6,\n",
    "    )\n",
    "    lstm_glove.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=sched, clipnorm=1.0),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    history_lstm_3 = lstm_glove.fit(\n",
    "        Xtr_pad,\n",
    "        y_train_enc,\n",
    "        validation_split=0.1,\n",
    "        epochs=6,\n",
    "        batch_size=batch_size_stage3,\n",
    "        class_weight=class_weight_keras_tuned,\n",
    "        callbacks=cb_lstm_stage3,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    # --- Evaluation ---\n",
    "    y_prob_lstm = lstm_glove.predict(Xte_pad, verbose=0)\n",
    "    y_pred_lstm = y_prob_lstm.argmax(axis=1)\n",
    "    y_proba_lstm = y_prob_lstm\n",
    "\n",
    "    add_result(\n",
    "        results_all,\n",
    "        \"BiLSTM+Attention (GloVe-Twitter)\",\n",
    "        acc=accuracy_score(y_test_enc, y_pred_lstm),\n",
    "        prec=precision_recall_fscore_support(y_test_enc, y_pred_lstm, average=\"macro\")[\n",
    "            0\n",
    "        ],\n",
    "        rec=precision_recall_fscore_support(y_test_enc, y_pred_lstm, average=\"macro\")[\n",
    "            1\n",
    "        ],\n",
    "        f1=precision_recall_fscore_support(y_test_enc, y_pred_lstm, average=\"macro\")[2],\n",
    "    )\n",
    "    print(\n",
    "        f\"[RESULT] BiLSTM+Attention (GloVe-Twitter): {accuracy_score(y_test_enc, y_pred_lstm):.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fefa159f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_textcnn(vocab_size, emb_matrix, max_len, num_classes, trainable=False):\n",
    "    emb_dim = emb_matrix.shape[1]\n",
    "    inp = layers.Input(shape=(max_len,), name=\"input_ids\")\n",
    "    x = layers.Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=emb_dim,\n",
    "        weights=[emb_matrix],\n",
    "        trainable=trainable,\n",
    "        name=\"embedding\",\n",
    "    )(inp)\n",
    "    x = layers.SpatialDropout1D(0.2, name=\"spatial_dropout\")(x)\n",
    "\n",
    "    branches = []\n",
    "    for k in (2, 3, 4, 5, 7):\n",
    "        b = layers.Conv1D(128, k, padding=\"same\", activation=None, name=f\"conv_{k}\")(x)\n",
    "        b = layers.BatchNormalization(name=f\"bn_{k}\")(b)\n",
    "        b = layers.Activation(\"relu\", name=f\"relu_{k}\")(b)\n",
    "        b = se_block(b)\n",
    "        branches.append(attention_pool(b))\n",
    "\n",
    "    h = layers.Concatenate(name=\"concat_branches\")(branches)\n",
    "    h = layers.Dropout(0.4, name=\"dropout_head\")(h)\n",
    "    h = layers.Dense(\n",
    "        192,\n",
    "        activation=\"relu\",\n",
    "        kernel_regularizer=regularizers.l2(1e-4),\n",
    "        name=\"dense_192\",\n",
    "    )(h)\n",
    "    h = layers.Dropout(0.4, name=\"dropout_192\")(h)\n",
    "    out = layers.Dense(num_classes, activation=\"softmax\", name=\"classifier\")(h)\n",
    "\n",
    "    model = models.Model(inp, out, name=\"TextCNN_TwitterSE_Attn\")\n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6875a039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CNN-SE] Tokenizing + Twitter embeddings + training...\n",
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1759691663.421268  122908 service.cc:152] XLA service 0x7ff06c8805d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1759691663.421318  122908 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Laptop GPU, Compute Capability 8.9\n",
      "2025-10-05 13:14:23.546495: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-10-05 13:14:26.972273: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 25.23GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-10-05 13:14:27.063010: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 25.23GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  2/126\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 65ms/step - accuracy: 0.2832 - loss: 3.5559  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1759691673.493167  122908 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m120/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3578 - loss: 2.6763"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 13:14:37.540679: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 22.37GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.3597 - loss: 2.6304"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 13:14:44.670276: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_879', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2025-10-05 13:14:46.637005: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_245', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-10-05 13:14:47.088130: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "2025-10-05 13:14:47.524890: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_879', 44 bytes spill stores, 44 bytes spill loads\n",
      "\n",
      "2025-10-05 13:14:48.056391: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 24.93GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-10-05 13:14:48.156606: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 24.93GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 124ms/step - accuracy: 0.3997 - loss: 1.6986 - val_accuracy: 0.5774 - val_loss: 1.0619 - learning_rate: 0.0010\n",
      "Epoch 2/12\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5671 - loss: 0.9205 - val_accuracy: 0.6663 - val_loss: 0.8613 - learning_rate: 0.0010\n",
      "Epoch 3/12\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6497 - loss: 0.7869 - val_accuracy: 0.7183 - val_loss: 0.6973 - learning_rate: 0.0010\n",
      "Epoch 4/12\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6927 - loss: 0.7182 - val_accuracy: 0.7323 - val_loss: 0.6361 - learning_rate: 0.0010\n",
      "Epoch 5/12\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7229 - loss: 0.6628 - val_accuracy: 0.7339 - val_loss: 0.6157 - learning_rate: 0.0010\n",
      "Epoch 6/12\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7443 - loss: 0.6158 - val_accuracy: 0.7490 - val_loss: 0.5823 - learning_rate: 0.0010\n",
      "Epoch 7/12\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7555 - loss: 0.5908 - val_accuracy: 0.7473 - val_loss: 0.5872 - learning_rate: 0.0010\n",
      "Epoch 8/12\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7783 - loss: 0.5536\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7807 - loss: 0.5463 - val_accuracy: 0.7468 - val_loss: 0.5830 - learning_rate: 0.0010\n",
      "Epoch 9/12\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8017 - loss: 0.4986 - val_accuracy: 0.7373 - val_loss: 0.5916 - learning_rate: 5.0000e-04\n",
      "Epoch 1/10\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 90ms/step - accuracy: 0.7699 - loss: 0.5530 - val_accuracy: 0.7412 - val_loss: 0.5810 - learning_rate: 1.0000e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7831 - loss: 0.5217 - val_accuracy: 0.7412 - val_loss: 0.5749 - learning_rate: 1.0000e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7873 - loss: 0.5073 - val_accuracy: 0.7468 - val_loss: 0.5662 - learning_rate: 1.0000e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7919 - loss: 0.4926 - val_accuracy: 0.7468 - val_loss: 0.5663 - learning_rate: 1.0000e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7990 - loss: 0.4778 - val_accuracy: 0.7490 - val_loss: 0.5588 - learning_rate: 1.0000e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8086 - loss: 0.4575 - val_accuracy: 0.7479 - val_loss: 0.5738 - learning_rate: 1.0000e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m124/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8133 - loss: 0.4637\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8152 - loss: 0.4555 - val_accuracy: 0.7529 - val_loss: 0.5593 - learning_rate: 1.0000e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8187 - loss: 0.4389 - val_accuracy: 0.7535 - val_loss: 0.5658 - learning_rate: 5.0000e-05\n",
      "Epoch 1/8\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8086 - loss: 0.4928"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 13:16:03.486075: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_245', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-10-05 13:16:04.210037: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 67ms/step - accuracy: 0.8099 - loss: 0.4869 - val_accuracy: 0.7529 - val_loss: 0.5639\n",
      "Epoch 2/8\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8075 - loss: 0.4892 - val_accuracy: 0.7507 - val_loss: 0.5586\n",
      "Epoch 3/8\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8145 - loss: 0.4788 - val_accuracy: 0.7513 - val_loss: 0.5611\n",
      "Epoch 4/8\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8160 - loss: 0.4707 - val_accuracy: 0.7541 - val_loss: 0.5622\n",
      "Epoch 5/8\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8209 - loss: 0.4668 - val_accuracy: 0.7518 - val_loss: 0.5638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 13:16:16.780612: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "2025-10-05 13:16:17.469657: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_764', 180 bytes spill stores, 180 bytes spill loads\n",
      "\n",
      "2025-10-05 13:16:19.977815: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "2025-10-05 13:16:21.005005: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_839', 212 bytes spill stores, 212 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT] CNN (Twitter SE+Attn): 0.7592\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "try:\n",
    "    glove_tw = api.load(\"glove-twitter-200\")\n",
    "except Exception as e:\n",
    "    print(\"[WARN] Could not download GloVe:\", e)\n",
    "    if os.path.exists(\"vectors/glove-twitter-200.kv\"):\n",
    "        glove_tw = KeyedVectors.load(\"vectors/glove-twitter-200.kv\")\n",
    "    else:\n",
    "        raise e\n",
    "\n",
    "if RUN_CNN_TWITTER_SE:\n",
    "    print(\"\\n[CNN-SE] Tokenizing + Twitter embeddings + training...\")\n",
    "\n",
    "    X_train_dl = X_train.str.replace(r\"\\bhash_\", \"\", regex=True)\n",
    "    X_test_dl = X_test.str.replace(r\"\\bhash_\", \"\", regex=True)\n",
    "\n",
    "    MAX_VOCAB = 50_000\n",
    "    MAX_LEN = 180\n",
    "\n",
    "    tok = Tokenizer(num_words=MAX_VOCAB, oov_token=\"<OOV>\")\n",
    "    tok.fit_on_texts(X_train_dl)\n",
    "\n",
    "    Xtr_seq = tok.texts_to_sequences(X_train_dl)\n",
    "    Xte_seq = tok.texts_to_sequences(X_test_dl)\n",
    "    Xtr_pad = pad_sequences(Xtr_seq, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "    Xte_pad = pad_sequences(Xte_seq, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "    VOCAB_SIZE = min(MAX_VOCAB, len(tok.word_index) + 1)\n",
    "\n",
    "    # --- Glove-Twitter Embeddings ---\n",
    "    emb_twitter = build_embedding_matrix(glove_tw, tok, MAX_VOCAB)\n",
    "    emb_twitter = emb_twitter[:VOCAB_SIZE, :]\n",
    "\n",
    "    if emb_twitter.shape[0] > 0:\n",
    "        emb_twitter[0] = 0.0\n",
    "\n",
    "    # --- Model ---\n",
    "    cnn_twitter = make_textcnn(\n",
    "        VOCAB_SIZE, emb_twitter, MAX_LEN, num_classes, trainable=False\n",
    "    )\n",
    "\n",
    "    cb_cnn_stage12 = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=3, restore_best_weights=True\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\", factor=0.5, patience=2, min_lr=1e-5, verbose=1\n",
    "        ),\n",
    "    ]\n",
    "    cb_cnn_stage3 = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=3, restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # --- Stage 1 ---\n",
    "    history_stage1 = cnn_twitter.fit(\n",
    "        Xtr_pad,\n",
    "        y_train_enc,\n",
    "        validation_split=0.1,\n",
    "        epochs=12,\n",
    "        batch_size=128,\n",
    "        callbacks=cb_cnn_stage12,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    # --- Stage 2 (unfreeze + class_weight) ---\n",
    "    cnn_twitter.get_layer(\"embedding\").trainable = True\n",
    "    cnn_twitter.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        optimizer=tf.keras.optimizers.Adam(1e-4, clipnorm=1.0),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    history_stage2 = cnn_twitter.fit(\n",
    "        Xtr_pad,\n",
    "        y_train_enc,\n",
    "        validation_split=0.1,\n",
    "        epochs=10,\n",
    "        batch_size=128,\n",
    "        callbacks=cb_cnn_stage12,\n",
    "        class_weight=class_weight_keras,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    # --- Stage 3 (fine-tuning with CosineDecayRestarts) ---\n",
    "    batch_size_stage3 = 64\n",
    "    steps_per_epoch = int(np.ceil(len(Xtr_pad) * 0.9 / batch_size_stage3))\n",
    "\n",
    "    sched = tf.keras.optimizers.schedules.CosineDecayRestarts(\n",
    "        initial_learning_rate=5e-5,\n",
    "        first_decay_steps=steps_per_epoch,\n",
    "        t_mul=2.0,\n",
    "        m_mul=0.9,\n",
    "        alpha=1e-6,\n",
    "    )\n",
    "    cnn_twitter.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=sched, clipnorm=1.0),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    history_stage3 = cnn_twitter.fit(\n",
    "        Xtr_pad,\n",
    "        y_train_enc,\n",
    "        validation_split=0.1,\n",
    "        epochs=8,\n",
    "        batch_size=batch_size_stage3,\n",
    "        callbacks=cb_cnn_stage3,\n",
    "        class_weight=class_weight_keras_tuned,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    # --- Final Evaluation ---\n",
    "    y_prob_cnn = cnn_twitter.predict(Xte_pad, verbose=0)\n",
    "    y_pred_cnn = y_prob_cnn.argmax(axis=1)\n",
    "    y_proba_cnn = y_prob_cnn\n",
    "    eval_and_add(results_all, \"CNN (Twitter SE+Attn)\", y_test_enc, y_pred_cnn)\n",
    "    print(\n",
    "        f\"[RESULT] CNN (Twitter SE+Attn): {accuracy_score(y_test_enc, y_pred_cnn):.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c637d95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# 5) TRANSFORMER – feature extractor + heads\n",
    "# ==============================================\n",
    "Xtr_emb, Xte_emb = None, None\n",
    "y_pred_roberta_ft = None\n",
    "eval_metrics_ft = None\n",
    "\n",
    "\n",
    "def encode_texts(\n",
    "    texts, tokenizer, model, device, batch_size=64, max_len=96, pooling=\"mean\"\n",
    "):\n",
    "    embs = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i : i + batch_size]\n",
    "            tok = tokenizer(\n",
    "                list(batch),\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=max_len,\n",
    "                return_tensors=\"pt\",\n",
    "            ).to(device)\n",
    "            out = model(**tok)\n",
    "            if pooling == \"cls\":\n",
    "                vec = out.last_hidden_state[:, 0, :]\n",
    "            else:\n",
    "                mask = tok.attention_mask.unsqueeze(-1)\n",
    "                summed = (out.last_hidden_state * mask).sum(dim=1)\n",
    "                counts = mask.sum(dim=1).clamp(min=1)\n",
    "                vec = summed / counts\n",
    "            embs.append(vec.detach().cpu().numpy().astype(\"float32\"))\n",
    "    return np.vstack(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a4ae721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_ROBERTA_FEATURES or RUN_ROBERTA_FINETUNE:\n",
    "    MODEL_NAME = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "    tok_hf = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e61b6fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[RoBERTa FE] Extracting embeddings + training traditional heads...\n",
      "[RESULT] RoBERTa feature extractor (LogReg head): 0.8868515205724508\n",
      "[RESULT] RoBERTa feature extractor (LinearSVC head): 0.8841681574239714\n"
     ]
    }
   ],
   "source": [
    "if RUN_ROBERTA_FEATURES:\n",
    "    print(\"\\n[RoBERTa FE] Extracting embeddings + training traditional heads...\")\n",
    "    backbone = AutoModel.from_pretrained(MODEL_NAME).to(DEVICE)\n",
    "\n",
    "    tr_path = CACHE_DIR / \"Xtr_roberta_mean96.npy\"\n",
    "    te_path = CACHE_DIR / \"Xte_roberta_mean96.npy\"\n",
    "    if tr_path.exists() and te_path.exists():\n",
    "        Xtr_emb = np.load(tr_path)\n",
    "        Xte_emb = np.load(te_path)\n",
    "    else:\n",
    "        Xtr_emb = encode_texts(\n",
    "            X_train.tolist(),\n",
    "            tok_hf,\n",
    "            backbone,\n",
    "            DEVICE,\n",
    "            max_len=96,\n",
    "            batch_size=64,\n",
    "            pooling=\"mean\",\n",
    "        )\n",
    "        Xte_emb = encode_texts(\n",
    "            X_test.tolist(),\n",
    "            tok_hf,\n",
    "            backbone,\n",
    "            DEVICE,\n",
    "            max_len=96,\n",
    "            batch_size=64,\n",
    "            pooling=\"mean\",\n",
    "        )\n",
    "        np.save(tr_path, Xtr_emb)\n",
    "        np.save(te_path, Xte_emb)\n",
    "\n",
    "    # Heads\n",
    "    lr_head = LogisticRegression(\n",
    "        max_iter=2000, C=1.0, n_jobs=-1, random_state=RANDOM_STATE\n",
    "    )\n",
    "    svm_head = LinearSVC(C=1.0, random_state=RANDOM_STATE)\n",
    "\n",
    "    lr_head.fit(Xtr_emb, y_train)\n",
    "    y_pred = lr_head.predict(Xte_emb)\n",
    "    y_proba_roberta_lr = lr_head.predict_proba(Xte_emb)\n",
    "    eval_and_add(results_all, \"RoBERTa feature extractor (LogReg head)\", y_test, y_pred)\n",
    "    print(\n",
    "        f\"[RESULT] RoBERTa feature extractor (LogReg head): {accuracy_score(y_test, y_pred)}\"\n",
    "    )\n",
    "\n",
    "    svm_head.fit(Xtr_emb, y_train)\n",
    "    y_pred = svm_head.predict(Xte_emb)\n",
    "    eval_and_add(\n",
    "        results_all, \"RoBERTa feature extractor (LinearSVC head)\", y_test, y_pred\n",
    "    )\n",
    "    print(\n",
    "        f\"[RESULT] RoBERTa feature extractor (LinearSVC head): {accuracy_score(y_test, y_pred)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71686b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[RoBERTa FT] Fine-tuning de twitter-roberta-base-sentiment-latest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/17888 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 17888/17888 [00:00<00:00, 21272.39 examples/s]\n",
      "Map: 100%|██████████| 4472/4472 [00:00<00:00, 22035.17 examples/s]\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3354' max='3354' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3354/3354 08:10, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.422000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.447300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.358300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.396600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.394700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.341100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.342700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.364900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.403900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.372100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.353400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.382200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.336300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.386700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.320200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.354500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.393000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.332900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.272600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.339200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.309800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.350700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.231500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.192400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.225500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.230500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.178100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.207000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.220300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.236300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.197800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.262800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.251000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.170600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.212100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.212300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.241300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.217700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.186300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.167900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.221700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.146500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.251100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.203500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.114200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.128300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.097500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.141500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.107500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.121400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.178200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>0.159200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.142000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.141700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>0.128200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.142200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>0.117200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.084900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>0.170900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.104600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>0.109100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.168600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.187300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.134900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>0.141500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT] RoBERTa fine-tuned (twitter-roberta-base-sentiment-latest): 0.8978085867620751\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 6) TRANSFORMER – fine-tuning\n",
    "# =================================\n",
    "if RUN_ROBERTA_FINETUNE:\n",
    "    print(\"\\n[RoBERTa FT] Fine-tuning twitter-roberta-base-sentiment-latest...\")\n",
    "\n",
    "    label2id = {lbl: i for i, lbl in enumerate(sorted(np.unique(y_train)))}\n",
    "    id2label = {i: lbl for lbl, i in label2id.items()}\n",
    "\n",
    "    def map_labels(y_list):\n",
    "        return [label2id[l] for l in y_list]\n",
    "\n",
    "    train_ds = Dataset.from_dict({\"text\": X_train.tolist(), \"label\": map_labels(y_train.tolist())})\n",
    "    test_ds  = Dataset.from_dict({\"text\": X_test.tolist(),  \"label\": map_labels(y_test.tolist())})\n",
    "\n",
    "    def tokenize_fn(batch):\n",
    "        return tok_hf(batch[\"text\"], truncation=True, padding=True, max_length=128)\n",
    "\n",
    "    train_ds = train_ds.map(tokenize_fn, batched=True)\n",
    "    test_ds  = test_ds.map(tokenize_fn, batched=True)\n",
    "\n",
    "    model_ft = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME, num_labels=len(label2id), id2label=id2label, label2id=label2id\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir=str(OUTDIR / \"roberta_finetuned\"),\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=32,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        logging_steps=50,\n",
    "        save_total_limit=1,\n",
    "        report_to=\"none\"\n",
    "    )\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        preds = logits.argmax(axis=1)\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        prec, rec, f1, _ = precision_recall_fscore_support(labels, preds, average=\"macro\")\n",
    "        return {\"accuracy\": acc, \"f1\": f1, \"precision\": prec, \"recall\": rec}\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model_ft, args=args,\n",
    "        train_dataset=train_ds, eval_dataset=test_ds,\n",
    "        tokenizer=tok_hf, compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    eval_metrics_ft = trainer.evaluate()\n",
    "\n",
    "    # Predictions of the fine-tuned model\n",
    "    pred_logits = trainer.predict(test_ds).predictions\n",
    "    import numpy as _np\n",
    "    y_proba_roberta_ft = _np.exp(pred_logits - _np.max(pred_logits, axis=1, keepdims=True))\n",
    "    y_proba_roberta_ft = y_proba_roberta_ft / _np.sum(y_proba_roberta_ft, axis=1, keepdims=True)\n",
    "    pred_ids = pred_logits.argmax(axis=1)\n",
    "    y_pred_roberta_ft = [id2label[i] for i in pred_ids]\n",
    "    eval_and_add(results_all, \"RoBERTa fine-tuned (twitter-roberta-base-sentiment-latest)\", y_test, y_pred_roberta_ft)\n",
    "    print(f\"[RESULT] RoBERTa fine-tuned (twitter-roberta-base-sentiment-latest): {accuracy_score(y_test, y_pred_roberta_ft)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb64a423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ensemble (Weighted Voting) ===\n",
      "Accuracy:  0.8090\n",
      "Precision: 0.8063\n",
      "Recall:    0.8152\n",
      "F1:        0.8090\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.87      0.81      1149\n",
      "     neutral       0.79      0.76      0.78      1638\n",
      "    positive       0.87      0.81      0.84      1685\n",
      "\n",
      "    accuracy                           0.81      4472\n",
      "   macro avg       0.81      0.82      0.81      4472\n",
      "weighted avg       0.81      0.81      0.81      4472\n",
      "\n",
      "\n",
      "=== Ensemble (Majority Voting) ===\n",
      "Accuracy:  0.8090\n",
      "Precision: 0.8063\n",
      "Recall:    0.8152\n",
      "F1:        0.8090\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.87      0.81      1149\n",
      "     neutral       0.79      0.76      0.78      1638\n",
      "    positive       0.87      0.81      0.84      1685\n",
      "\n",
      "    accuracy                           0.81      4472\n",
      "   macro avg       0.81      0.82      0.81      4472\n",
      "weighted avg       0.81      0.81      0.81      4472\n",
      "\n",
      "\n",
      ">>> Best ensamble: Ensemble (Weighted Voting) | Acc=0.8090 Prec=0.8063 Rec=0.8152 F1=0.8090\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    ")\n",
    "\n",
    "if RUN_ENSEMBLE_MODELS:\n",
    "\n",
    "    def to_labels(y_pred):\n",
    "        if y_pred is None or len(y_pred) == 0:\n",
    "            return None\n",
    "        if isinstance(y_pred[0], str):\n",
    "            return np.array(y_pred, dtype=object)\n",
    "        return le.inverse_transform(np.array(y_pred)).astype(object)\n",
    "\n",
    "    y_pred_roberta_ft_text = to_labels(y_pred_roberta_ft)\n",
    "    y_pred_lstm_text = to_labels(y_pred_lstm)\n",
    "    y_pred_cnn_text = to_labels(y_pred_cnn)\n",
    "\n",
    "    def safe_zip(*arrays):\n",
    "        maxlen = max(len(a) for a in arrays if a is not None)\n",
    "        filled = []\n",
    "        for a in arrays:\n",
    "            if a is None:\n",
    "                filled.append([None] * maxlen)\n",
    "            else:\n",
    "                filled.append(a)\n",
    "        return zip(*filled)\n",
    "\n",
    "    y_pred_roberta_ft = to_labels(y_pred_roberta_ft)\n",
    "    y_pred_lstm = to_labels(y_pred_lstm)\n",
    "    y_pred_cnn = to_labels(y_pred_cnn)\n",
    "\n",
    "    y_true = to_labels(y_test_enc)\n",
    "\n",
    "    # ======================\n",
    "    # 1) WEIGHTED VOTING\n",
    "    # ======================\n",
    "    weights = {\"roberta\": 0.90, \"lstm\": 0.76, \"cnn\": 0.75}\n",
    "\n",
    "    def weighted_vote(roberta, lstm, cnn):\n",
    "        votes = Counter()\n",
    "        if roberta is not None:\n",
    "            votes[roberta] += weights[\"roberta\"]\n",
    "        if lstm is not None:\n",
    "            votes[lstm] += weights[\"lstm\"]\n",
    "        if cnn is not None:\n",
    "            votes[cnn] += weights[\"cnn\"]\n",
    "\n",
    "        if not votes:\n",
    "            return None\n",
    "\n",
    "        top = votes.most_common(2)\n",
    "        # No tie\n",
    "        if len(top) == 1 or top[0][1] != top[1][1]:\n",
    "            return top[0][0]\n",
    "\n",
    "        # Tie: priorize RoBERTa if tied\n",
    "        tied_weight = top[0][1]\n",
    "        tied_labels = {lbl for lbl, w in top if w == tied_weight}\n",
    "        if roberta in tied_labels:\n",
    "            return roberta\n",
    "        return top[0][0]\n",
    "\n",
    "    y_pred_ens_weighted = np.array(\n",
    "        [\n",
    "            weighted_vote(r, l, c)\n",
    "            for r, l, c in safe_zip(\n",
    "                y_pred_roberta_ft_text, y_pred_lstm_text, y_pred_cnn_text\n",
    "            )\n",
    "        ],\n",
    "        dtype=object,\n",
    "    )\n",
    "\n",
    "    mask_w = y_pred_ens_weighted != None\n",
    "\n",
    "    acc_w = accuracy_score(y_true[mask_w], y_pred_ens_weighted[mask_w])\n",
    "    prec_w, rec_w, f1_w, _ = precision_recall_fscore_support(\n",
    "        y_true[mask_w], y_pred_ens_weighted[mask_w], average=\"macro\"\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== Ensemble (Weighted Voting) ===\")\n",
    "    print(f\"Accuracy:  {acc_w:.4f}\")\n",
    "    print(f\"Precision: {prec_w:.4f}\")\n",
    "    print(f\"Recall:    {rec_w:.4f}\")\n",
    "    print(f\"F1:        {f1_w:.4f}\")\n",
    "    print(classification_report(y_true[mask_w], y_pred_ens_weighted[mask_w]))\n",
    "\n",
    "    add_result(\n",
    "        results_all,\n",
    "        \"Ensemble (Weighted Voting)\",\n",
    "        acc=acc_w,\n",
    "        prec=prec_w,\n",
    "        rec=rec_w,\n",
    "        f1=f1_w,\n",
    "    )\n",
    "\n",
    "    # ======================\n",
    "    # 2) MAJORITY VOTING\n",
    "    # ======================\n",
    "    def majority_vote(roberta, lstm, cnn):\n",
    "        votes = Counter()\n",
    "        if roberta is not None:\n",
    "            votes[roberta] += 1.0\n",
    "        if lstm is not None:\n",
    "            votes[lstm] += 1.0\n",
    "        if cnn is not None:\n",
    "            votes[cnn] += 1.0\n",
    "\n",
    "        if not votes:\n",
    "            return None\n",
    "\n",
    "        top = votes.most_common(2)\n",
    "        # Clear majority\n",
    "        if len(top) == 1 or top[0][1] != top[1][1]:\n",
    "            return top[0][0]\n",
    "\n",
    "        # Tie: priorize RoBERTa if tied\n",
    "        tied_count = top[0][1]\n",
    "        tied_labels = {lbl for lbl, c in top if c == tied_count}\n",
    "        if roberta in tied_labels:\n",
    "            return roberta\n",
    "        return top[0][0]\n",
    "\n",
    "    y_pred_ens_majority = np.array(\n",
    "        [\n",
    "            majority_vote(r, l, c)\n",
    "            for r, l, c in safe_zip(\n",
    "                y_pred_roberta_ft_text, y_pred_lstm_text, y_pred_cnn_text\n",
    "            )\n",
    "        ],\n",
    "        dtype=object,\n",
    "    )\n",
    "\n",
    "    mask_m = y_pred_ens_majority != None\n",
    "\n",
    "    acc_m = accuracy_score(y_true[mask_m], y_pred_ens_majority[mask_m])\n",
    "    prec_m, rec_m, f1_m, _ = precision_recall_fscore_support(\n",
    "        y_true[mask_m], y_pred_ens_majority[mask_m], average=\"macro\"\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== Ensemble (Majority Voting) ===\")\n",
    "    print(f\"Accuracy:  {acc_m:.4f}\")\n",
    "    print(f\"Precision: {prec_m:.4f}\")\n",
    "    print(f\"Recall:    {rec_m:.4f}\")\n",
    "    print(f\"F1:        {f1_m:.4f}\")\n",
    "    print(classification_report(y_true[mask_m], y_pred_ens_majority[mask_m]))\n",
    "\n",
    "    add_result(\n",
    "        results_all,\n",
    "        \"Ensemble (Majority Voting)\",\n",
    "        acc=acc_m,\n",
    "        prec=prec_m,\n",
    "        rec=rec_m,\n",
    "        f1=f1_m,\n",
    "    )\n",
    "\n",
    "    # Select the best ensemble\n",
    "    if f1_w >= f1_m:\n",
    "        y_pred_ens = y_pred_ens_weighted\n",
    "        ens_name = \"Ensemble (Weighted Voting)\"\n",
    "        best_scores = (acc_w, prec_w, rec_w, f1_w)\n",
    "    else:\n",
    "        y_pred_ens = y_pred_ens_majority\n",
    "        ens_name = \"Ensemble (Majority Voting)\"\n",
    "        best_scores = (acc_m, prec_m, rec_m, f1_m)\n",
    "\n",
    "    print(\n",
    "        f\"\\n>>> Best ensemble: {ens_name} | Acc={best_scores[0]:.4f} Prec={best_scores[1]:.4f} Rec={best_scores[2]:.4f} F1={best_scores[3]:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18495b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "✅ Models added: 10\n",
      "============================================================\n",
      "                                                     Model  Accuracy  Precision  Recall     F1\n",
      "RoBERTa fine-tuned (twitter-roberta-base-sentiment-latest)    0.8978     0.8975  0.9011 0.8990\n",
      "                   RoBERTa feature extractor (LogReg head)    0.8869     0.8892  0.8890 0.8891\n",
      "                RoBERTa feature extractor (LinearSVC head)    0.8842     0.8867  0.8861 0.8863\n",
      "                                Ensemble (Weighted Voting)    0.8090     0.8063  0.8152 0.8090\n",
      "                                Ensemble (Majority Voting)    0.8090     0.8063  0.8152 0.8090\n",
      "                          BiLSTM+Attention (GloVe-Twitter)    0.7641     0.7621  0.7693 0.7642\n",
      "                                     CNN (Twitter SE+Attn)    0.7592     0.7571  0.7669 0.7593\n",
      "                              Logistic Regression (TF-IDF)    0.7068     0.7050  0.7119 0.7078\n",
      "                                        LinearSVC (TF-IDF)    0.6986     0.7001  0.6990 0.6994\n",
      "                                     RandomForest (TF-IDF)    0.6773     0.6869  0.6719 0.6774\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 7) RESUMES, TABLES AND GRAPHS\n",
    "# ================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"✅ Models added: {len(results_all)}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "df_results_all = pd.DataFrame(results_all).sort_values(\"F1\", ascending=False)\n",
    "print(df_results_all.to_string(index=False))\n",
    "# Save to csv\n",
    "df_results_all.to_csv(\"model_results.csv\", index=False)\n",
    "# Save to json\n",
    "with open(\"model_results.json\", \"w\") as f:\n",
    "    json.dump(results_all, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6d3a5737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comparison graph\n",
    "if MAKE_FIGURES and not df_results_all.empty:\n",
    "    plt.figure(figsize=(9, 5))\n",
    "    plt.barh(df_results_all[\"Model\"], df_results_all[\"F1\"])\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title(\"Comparación de modelos (F1-score)\")\n",
    "    plt.xlabel(\"F1-score\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"model_f1_comparison.png\", dpi=160)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0d1de89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 450x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix of the best available model\n",
    "best_name = None\n",
    "y_pred_best = None\n",
    "if y_pred_roberta_ft is not None:\n",
    "    best_name = \"RoBERTa FT\"\n",
    "    y_pred_best = y_pred_roberta_ft\n",
    "elif RUN_CNN_TWITTER_SE and Xte_pad is not None:\n",
    "    best_name = \"CNN (Twitter SE+Attn)\"\n",
    "    y_pred_best = le.inverse_transform(y_pred_cnn) if \"y_pred_cnn\" in locals() else None\n",
    "elif RUN_TFIDF_MODELS and \"log_reg\" in locals():\n",
    "    best_name = \"Logistic Regression (TF-IDF)\"\n",
    "    y_pred_best = log_reg.predict(X_test_tfidf) if X_test_tfidf is not None else None\n",
    "\n",
    "if MAKE_FIGURES and y_pred_best is not None:\n",
    "    labels_order = [\"negative\", \"neutral\", \"positive\"]\n",
    "    cm = confusion_matrix(y_test, y_pred_best, labels=labels_order)\n",
    "    plt.figure(figsize=(4.5, 4))\n",
    "    plt.imshow(cm, interpolation=\"nearest\")\n",
    "    plt.title(f\"Confusion Matrix – {best_name}\")\n",
    "    plt.xticks(range(len(labels_order)), [\"neg\", \"neu\", \"pos\"])\n",
    "    plt.yticks(range(len(labels_order)), [\"neg\", \"neu\", \"pos\"])\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"confusion_matrix_best.png\", dpi=160)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "27b0e028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 8) PER-EXAMPLE PREDICTIONS\n",
    "# =========================\n",
    "def safe_predict(model, X, name):\n",
    "    try:\n",
    "        return model.predict(X)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Could not predict with {name}: {e}\")\n",
    "        return pd.Series([None] * len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "42f264ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_preds = pd.DataFrame(\n",
    "    {\"text\": X_test.reset_index(drop=True), \"true\": y_test.reset_index(drop=True)}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "47a57b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_TFIDF_MODELS and X_test_tfidf is not None:\n",
    "    if \"log_reg\" in locals():\n",
    "        df_all_preds[\"pred_lr_tfidf\"] = pd.Series(\n",
    "            safe_predict(log_reg, X_test_tfidf, \"LR TF-IDF\")\n",
    "        )\n",
    "    if \"svm_clf\" in locals():\n",
    "        df_all_preds[\"pred_svm_tfidf\"] = pd.Series(\n",
    "            safe_predict(svm_clf, X_test_tfidf, \"LinearSVC TF-IDF\")\n",
    "        )\n",
    "    if \"rf_clf\" in locals():\n",
    "        df_all_preds[\"pred_rf_tfidf\"] = pd.Series(\n",
    "            safe_predict(rf_clf, X_test_tfidf, \"RF TF-IDF\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9104c37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_text_labels(arr, le):\n",
    "    if arr is None:\n",
    "        return None\n",
    "    arr = np.asarray(arr)\n",
    "    if arr.size == 0:\n",
    "        return arr\n",
    "    if arr.dtype == object or isinstance(arr[0], str):\n",
    "        return arr.astype(object)\n",
    "    return le.inverse_transform(arr.astype(int)).astype(object)\n",
    "\n",
    "if RUN_CNN_TWITTER_SE and Xte_pad is not None and \"y_pred_cnn\" in locals():\n",
    "    df_all_preds[\"pred_cnn_twitter_se\"] = pd.Series(\n",
    "        ensure_text_labels(y_pred_cnn, le)\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "if RUN_LSTM_BIATTN and Xte_pad is not None and \"y_pred_lstm\" in locals():\n",
    "    df_all_preds[\"pred_lstm_biattn\"] = pd.Series(\n",
    "        ensure_text_labels(y_pred_lstm, le)\n",
    "    ).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5a7699e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_ROBERTA_FEATURES and Xte_emb is not None:\n",
    "    if \"lr_head\" in locals():\n",
    "        df_all_preds[\"pred_roberta_lr\"] = pd.Series(\n",
    "            safe_predict(lr_head, Xte_emb, \"RoBERTa + LR head\")\n",
    "        )\n",
    "    if \"svm_head\" in locals():\n",
    "        df_all_preds[\"pred_roberta_svm\"] = pd.Series(\n",
    "            safe_predict(svm_head, Xte_emb, \"RoBERTa + SVM head\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1a94b689",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_ROBERTA_FINETUNE and y_pred_roberta_ft is not None:\n",
    "    df_all_preds[\"pred_roberta_finetuned\"] = pd.Series(y_pred_roberta_ft).reset_index(\n",
    "        drop=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "14625d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Saved per-example predictions in: /mnt/i/My Drive/Maestría En Ciencia de Datos/Tercer Trimestre/NLP/FinalProject-WorldCup-TweetClassification/fifa-wc-tweets-sentiment-classifier/SCRITPS/all_model_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "if SAVE_PER_EXAMPLE_CSV:\n",
    "    OUTDIR = Path(\"\")\n",
    "    out_csv = OUTDIR / \"all_model_predictions.csv\"\n",
    "    df_all_preds.to_csv(out_csv, index=False)\n",
    "    print(f\"\\n[INFO] Saved per-example predictions in: {out_csv.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "899922c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(context=\"notebook\", style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.autolayout\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3816b132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_table(df: pd.DataFrame, name: str):\n",
    "    csv_path = TABDIR / f\"{name}.csv\"\n",
    "    tex_path = TABDIR / f\"{name}.tex\"\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    try:\n",
    "        with open(tex_path, \"w\") as f:\n",
    "            f.write(df.to_latex(index=False, escape=True))\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] No pude exportar LaTeX para {name}: {e}\")\n",
    "    print(f\"[SAVED] Tables → {csv_path.name}, {tex_path.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fa9afbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report_df(y_true, y_pred, labels=None):\n",
    "    rep = classification_report(\n",
    "        y_true, y_pred, labels=labels, output_dict=True, zero_division=0\n",
    "    )\n",
    "    return pd.DataFrame(rep).reset_index().rename(columns={\"index\": \"class\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a390c8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, labels, title, fname_prefix):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    ax = sns.heatmap(\n",
    "        cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels\n",
    "    )\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    plt.title(title)\n",
    "    out = FIGDIR / f\"{fname_prefix}_cm.png\"\n",
    "    plt.savefig(out, dpi=160)\n",
    "    plt.close()\n",
    "    print(f\"[FIG] {out.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b10ecbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_curves(histories: dict, title_prefix: str):\n",
    "    for name, h in histories.items():\n",
    "        if h is None:\n",
    "            continue\n",
    "        hist = pd.DataFrame(h.history)\n",
    "        # Accuracy\n",
    "        plt.figure(figsize=(6.2, 4.2))\n",
    "        if \"accuracy\" in hist:\n",
    "            plt.plot(hist[\"accuracy\"], label=\"train\")\n",
    "        if \"val_accuracy\" in hist:\n",
    "            plt.plot(hist[\"val_accuracy\"], label=\"val\")\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.title(f\"{title_prefix} – {name} (accuracy)\")\n",
    "        out = (\n",
    "            FIGDIR\n",
    "            / f\"{title_prefix.lower().replace(' ','_')}_{name.lower().replace(' ','_').replace('/','-')}_acc.png\"\n",
    "        )\n",
    "        plt.savefig(out, dpi=160)\n",
    "        plt.close()\n",
    "        print(f\"[FIG] {out.name}\")\n",
    "        # Loss\n",
    "        plt.figure(figsize=(6.2, 4.2))\n",
    "        if \"loss\" in hist:\n",
    "            plt.plot(hist[\"loss\"], label=\"train\")\n",
    "        if \"val_loss\" in hist:\n",
    "            plt.plot(hist[\"val_loss\"], label=\"val\")\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(f\"{title_prefix} – {name} (loss)\")\n",
    "        out = (\n",
    "            FIGDIR\n",
    "            / f\"{title_prefix.lower().replace(' ','_')}_{name.lower().replace(' ','_').replace('/','-')}_loss.png\"\n",
    "        )\n",
    "        plt.savefig(out, dpi=160)\n",
    "        plt.close()\n",
    "        print(f\"[FIG] {out.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb9ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import (\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    precision_recall_curve,\n",
    "    average_precision_score,\n",
    ")\n",
    "\n",
    "\n",
    "def plot_roc_pr_curves(y_true_text, proba_dict: dict, labels: list, prefix: str):\n",
    "    classes = labels\n",
    "    mapper = {c: i for i, c in enumerate(classes)}\n",
    "    y_true_idx = pd.Series(y_true_text).map(mapper).values\n",
    "    y_true_bin = label_binarize(y_true_idx, classes=list(range(len(classes))))\n",
    "    for name, probs in proba_dict.items():\n",
    "        if probs is None:\n",
    "            continue\n",
    "        if probs.shape[1] != len(classes):\n",
    "            print(f\"[WARN] ROC/PR ignored for {name} due to class mismatch.\")\n",
    "            continue\n",
    "        # ROC macro\n",
    "        fpr_dict, tpr_dict = {}, {}\n",
    "        for i in range(len(classes)):\n",
    "            fpr_dict[i], tpr_dict[i], _ = roc_curve(y_true_bin[:, i], probs[:, i])\n",
    "        all_fpr = np.unique(np.concatenate([fpr_dict[i] for i in range(len(classes))]))\n",
    "        mean_tpr = np.zeros_like(all_fpr)\n",
    "        for i in range(len(classes)):\n",
    "            mean_tpr += np.interp(all_fpr, fpr_dict[i], tpr_dict[i])\n",
    "        mean_tpr /= len(classes)\n",
    "        roc_auc_macro = auc(all_fpr, mean_tpr)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(all_fpr, mean_tpr, label=f\"macro AUC={roc_auc_macro:.3f}\")\n",
    "        plt.plot([0, 1], [0, 1], \"--\")\n",
    "        plt.xlabel(\"FPR\")\n",
    "        plt.ylabel(\"TPR\")\n",
    "        plt.title(f\"ROC (macro) – {name}\")\n",
    "        out = FIGDIR / f\"{prefix}_{name.lower().replace(' ','_')}_roc_macro.png\"\n",
    "        plt.legend()\n",
    "        plt.savefig(out, dpi=160)\n",
    "        plt.close()\n",
    "        print(f\"[FIG] {out.name}\")\n",
    "        # PR macro\n",
    "        grid = np.linspace(0, 1, 200)\n",
    "        mean_prec, aps = np.zeros_like(grid), []\n",
    "        for i in range(len(classes)):\n",
    "            pr, rc, _ = precision_recall_curve(y_true_bin[:, i], probs[:, i])\n",
    "            ap = average_precision_score(y_true_bin[:, i], probs[:, i])\n",
    "            aps.append(ap)\n",
    "            mean_prec += np.interp(grid, rc[::-1], pr[::-1])\n",
    "        mean_prec /= len(classes)\n",
    "        plt.figure(figsize=(6.2, 4.6))\n",
    "        plt.plot(grid, mean_prec, label=f\"macro AP={np.mean(aps):.3f}\")\n",
    "        plt.xlabel(\"Recall\")\n",
    "        plt.ylabel(\"Precision\")\n",
    "        plt.title(f\"PR (macro) – {name}\")\n",
    "        out = FIGDIR / f\"{prefix}_{name.lower().replace(' ','_')}_pr_macro.png\"\n",
    "        plt.legend()\n",
    "        plt.savefig(out, dpi=160)\n",
    "        plt.close()\n",
    "        print(f\"[FIG] {out.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "12b468e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_umap(\n",
    "    embeddings: np.ndarray,\n",
    "    labels_text: np.ndarray,\n",
    "    title: str,\n",
    "    fname_prefix: str,\n",
    "    max_points: int = 4000,\n",
    "):\n",
    "    n = embeddings.shape[0]\n",
    "    idx = np.random.RandomState(42).choice(n, size=min(max_points, n), replace=False)\n",
    "    Z = embeddings[idx]\n",
    "    lbls = np.array(labels_text)[idx]\n",
    "    reducer = umap.UMAP(\n",
    "        n_neighbors=15, min_dist=0.1, metric=\"cosine\", random_state=RANDOM_STATE\n",
    "    )\n",
    "    Z2 = reducer.fit_transform(Z)\n",
    "    plt.figure(figsize=(6.2, 5.6))\n",
    "    sns.scatterplot(x=Z2[:, 0], y=Z2[:, 1], hue=lbls, s=16, alpha=0.85, edgecolor=None)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"UMAP-1\")\n",
    "    plt.ylabel(\"UMAP-2\")\n",
    "    plt.legend(title=\"Clase\")\n",
    "    out = FIGDIR / f\"{fname_prefix}_umap.png\"\n",
    "    plt.savefig(out, dpi=160)\n",
    "    plt.close()\n",
    "    print(f\"[FIG] {out.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0d3f2e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EDA] Class distribution (raw):\n",
      "Sentiment\n",
      "positive    8425\n",
      "neutral     8188\n",
      "negative    5747\n",
      "Name: count, dtype: int64\n",
      "[EDA] Tweet length (mean/std/min/max): 134.64485688729874 77.34260510109583 18 405\n"
     ]
    }
   ],
   "source": [
    "df[\"tweet_len\"] = df[\"Tweet\"].astype(str).str.len()\n",
    "print(\"[EDA] Class distribution (raw):\")\n",
    "print(df[\"Sentiment\"].value_counts(dropna=False))\n",
    "print(\n",
    "    \"[EDA] Tweet length (mean/std/min/max):\",\n",
    "    df[\"tweet_len\"].mean(),\n",
    "    df[\"tweet_len\"].std(),\n",
    "    df[\"tweet_len\"].min(),\n",
    "    df[\"tweet_len\"].max(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "539827ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FIG] class_distribution_full.png\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(5.8, 4.2))\n",
    "sns.countplot(data=df, x=\"Sentiment\", order=sorted(df[\"Sentiment\"].unique()))\n",
    "plt.title(\"Class distribution (full dataset)\")\n",
    "out = FIGDIR / \"class_distribution_full.png\"\n",
    "plt.savefig(out, dpi=160)\n",
    "plt.close()\n",
    "print(f\"[FIG] {out.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8e2e99b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FIG] tweet_length_hist.png\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(6.4, 4.0))\n",
    "sns.histplot(df[\"tweet_len\"], bins=40, kde=True)\n",
    "plt.title(\"Tweet Length Distribution (characters)\")\n",
    "out = FIGDIR / \"tweet_length_hist.png\"\n",
    "plt.savefig(out, dpi=160)\n",
    "plt.close()\n",
    "print(f\"[FIG] {out.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "959c35cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     Model  Accuracy  Precision  Recall     F1\n",
      "RoBERTa fine-tuned (twitter-roberta-base-sentiment-latest)    0.8978     0.8975  0.9011 0.8990\n",
      "                   RoBERTa feature extractor (LogReg head)    0.8869     0.8892  0.8890 0.8891\n",
      "                RoBERTa feature extractor (LinearSVC head)    0.8842     0.8867  0.8861 0.8863\n",
      "                                Ensemble (Weighted Voting)    0.8090     0.8063  0.8152 0.8090\n",
      "                                Ensemble (Majority Voting)    0.8090     0.8063  0.8152 0.8090\n",
      "                          BiLSTM+Attention (GloVe-Twitter)    0.7641     0.7621  0.7693 0.7642\n",
      "                                     CNN (Twitter SE+Attn)    0.7592     0.7571  0.7669 0.7593\n",
      "                              Logistic Regression (TF-IDF)    0.7068     0.7050  0.7119 0.7078\n",
      "                                        LinearSVC (TF-IDF)    0.6986     0.7001  0.6990 0.6994\n",
      "                                     RandomForest (TF-IDF)    0.6773     0.6869  0.6719 0.6774\n",
      "[SAVED] Tables → model_comparison_metrics.csv, model_comparison_metrics.tex\n",
      "[FIG] model_f1_comparison.png\n",
      "[FIG] logistic_regression_(tf-idf)_cm.png\n",
      "[SAVED] Tables → classification_report__logistic_regression_(tf-idf).csv, classification_report__logistic_regression_(tf-idf).tex\n",
      "[FIG] linearsvc_(tf-idf)_cm.png\n",
      "[SAVED] Tables → classification_report__linearsvc_(tf-idf).csv, classification_report__linearsvc_(tf-idf).tex\n",
      "[FIG] randomforest_(tf-idf)_cm.png\n",
      "[SAVED] Tables → classification_report__randomforest_(tf-idf).csv, classification_report__randomforest_(tf-idf).tex\n",
      "[FIG] roberta_feature_extractor_(linearsvc_head)_cm.png\n",
      "[SAVED] Tables → classification_report__roberta_feature_extractor_(linearsvc_head).csv, classification_report__roberta_feature_extractor_(linearsvc_head).tex\n",
      "[FIG] roberta_feature_extractor_(logreg_head)_cm.png\n",
      "[SAVED] Tables → classification_report__roberta_feature_extractor_(logreg_head).csv, classification_report__roberta_feature_extractor_(logreg_head).tex\n",
      "[FIG] roberta_fine-tuned_(twitter-roberta-base-sentiment-latest)_cm.png\n",
      "[SAVED] Tables → classification_report__roberta_fine-tuned_(twitter-roberta-base-sentiment-latest).csv, classification_report__roberta_fine-tuned_(twitter-roberta-base-sentiment-latest).tex\n",
      "[FIG] curves_logistic_regression_(tf-idf)_roc_macro.png\n",
      "[FIG] curves_logistic_regression_(tf-idf)_pr_macro.png\n",
      "[FIG] curves_randomforest_(tf-idf)_roc_macro.png\n",
      "[FIG] curves_randomforest_(tf-idf)_pr_macro.png\n",
      "[FIG] curves_cnn_(twitter_se+attn)_roc_macro.png\n",
      "[FIG] curves_cnn_(twitter_se+attn)_pr_macro.png\n",
      "[FIG] curves_bilstm+attention_(glove-twitter)_roc_macro.png\n",
      "[FIG] curves_bilstm+attention_(glove-twitter)_pr_macro.png\n",
      "[FIG] curves_roberta_feature_extractor_(logreg_head)_roc_macro.png\n",
      "[FIG] curves_roberta_feature_extractor_(logreg_head)_pr_macro.png\n",
      "[FIG] curves_roberta_fine-tuned_(twitter-roberta-base-sentiment-latest)_roc_macro.png\n",
      "[FIG] curves_roberta_fine-tuned_(twitter-roberta-base-sentiment-latest)_pr_macro.png\n",
      "[BEST] RoBERTa fine-tuned (twitter-roberta-base-sentiment-latest) | Acc=0.8978 Prec=0.8975 Rec=0.9011 F1=0.899\n",
      "[FIG] best_model_cm.png\n",
      "[SAVED] Tables → best_model_classification_report.csv, best_model_classification_report.tex\n"
     ]
    }
   ],
   "source": [
    "df_results_all = pd.DataFrame(results_all).sort_values(\"F1\", ascending=False)\n",
    "print(df_results_all.to_string(index=False))\n",
    "save_table(df_results_all, \"model_comparison_metrics\")\n",
    "\n",
    "if MAKE_FIGURES and not df_results_all.empty:\n",
    "    plt.figure(figsize=(9, 5))\n",
    "    ax = sns.barplot(data=df_results_all, y=\"Model\", x=\"F1\", orient=\"h\")\n",
    "    ax.invert_yaxis()\n",
    "    plt.title(\"Model Comparison (F1-score)\")\n",
    "    plt.xlabel(\"F1-score (macro)\")\n",
    "    out = FIGDIR / \"model_f1_comparison.png\"\n",
    "    plt.savefig(out, dpi=160); plt.close(); print(f\"[FIG] {out.name}\")\n",
    "\n",
    "labels_order = ['negative','neutral','positive']\n",
    "\n",
    "preds_map = {}\n",
    "if RUN_TFIDF_MODELS:\n",
    "    if 'log_reg' in locals():\n",
    "        preds_map[\"Logistic Regression (TF-IDF)\"] = log_reg.predict(X_test_tfidf)\n",
    "    if 'svm_clf' in locals():\n",
    "        preds_map[\"LinearSVC (TF-IDF)\"] = svm_clf.predict(X_test_tfidf)\n",
    "    if 'rf_clf' in locals():\n",
    "        preds_map[\"RandomForest (TF-IDF)\"] = rf_clf.predict(X_test_tfidf)\n",
    "\n",
    "def ensure_text_labels(arr, le):\n",
    "    if arr is None:\n",
    "        return None\n",
    "    arr = np.asarray(arr)\n",
    "    if arr.size == 0:\n",
    "        return arr\n",
    "    if arr.dtype == object or isinstance(arr[0], str):\n",
    "        return arr.astype(object)\n",
    "    return le.inverse_transform(arr.astype(int)).astype(object)\n",
    "\n",
    "if RUN_CNN_TWITTER_SE and Xte_pad is not None and 'y_pred_cnn' in locals():\n",
    "    df_all_preds[\"pred_cnn_twitter_se\"] = pd.Series(ensure_text_labels(y_pred_cnn, le)).reset_index(drop=True)\n",
    "\n",
    "if RUN_LSTM_BIATTN and Xte_pad is not None and 'y_pred_lstm' in locals():\n",
    "    df_all_preds[\"pred_lstm_biattn\"] = pd.Series(ensure_text_labels(y_pred_lstm, le)).reset_index(drop=True)\n",
    "\n",
    "if RUN_ROBERTA_FEATURES and 'svm_head' in locals():\n",
    "    try:\n",
    "        preds_map[\"RoBERTa feature extractor (LinearSVC head)\"] = svm_head.predict(Xte_emb)\n",
    "    except Exception:\n",
    "        pass\n",
    "if RUN_ROBERTA_FEATURES and 'lr_head' in locals():\n",
    "    preds_map[\"RoBERTa feature extractor (LogReg head)\"] = lr_head.predict(Xte_emb)\n",
    "if RUN_ROBERTA_FINETUNE and y_pred_roberta_ft is not None:\n",
    "    preds_map[\"RoBERTa fine-tuned (twitter-roberta-base-sentiment-latest)\"] = y_pred_roberta_ft\n",
    "\n",
    "# Confusion matrices + classification reports by model\n",
    "for mname, yhat in preds_map.items():\n",
    "    plot_confusion_matrix(y_test, yhat, labels_order, f\"Confusion Matrix – {mname}\", mname.lower().replace(' ','_').replace('/','-'))\n",
    "    rep_df = classification_report_df(y_test, yhat, labels=labels_order)\n",
    "    save_table(rep_df, f\"classification_report__{mname.lower().replace(' ','_').replace('/','-')}\")\n",
    "\n",
    "# ROC/PR curves (macro) for models where probabilities are available\n",
    "proba_map = {\n",
    "    \"Logistic Regression (TF-IDF)\": locals().get(\"y_proba_lr\", None),\n",
    "    \"RandomForest (TF-IDF)\": locals().get(\"y_proba_rf\", None),\n",
    "    \"CNN (Twitter SE+Attn)\": locals().get(\"y_proba_cnn\", None),\n",
    "    \"BiLSTM+Attention (GloVe-Twitter)\": locals().get(\"y_proba_lstm\", None),\n",
    "    \"RoBERTa feature extractor (LogReg head)\": locals().get(\"y_proba_roberta_lr\", None),\n",
    "    \"RoBERTa fine-tuned (twitter-roberta-base-sentiment-latest)\": locals().get(\"y_proba_roberta_ft\", None),\n",
    "}\n",
    "plot_roc_pr_curves(y_test.values, proba_map, labels_order, prefix=\"curves\")\n",
    "\n",
    "# Summary of the best model\n",
    "best_row = df_results_all.iloc[0]\n",
    "best_model_name = best_row[\"Model\"]\n",
    "print(f\"[BEST] {best_model_name} | Acc={best_row['Accuracy']} Prec={best_row['Precision']} Rec={best_row['Recall']} F1={best_row['F1']}\")\n",
    "if best_model_name in preds_map:\n",
    "    plot_confusion_matrix(y_test, preds_map[best_model_name], labels_order, f\"Confusion Matrix – {best_model_name}\", \"best_model\")\n",
    "    rep_df = classification_report_df(y_test, preds_map[best_model_name], labels=labels_order)\n",
    "    save_table(rep_df, \"best_model_classification_report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0761b588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FIG] bilstm+attention_lstm_stage1_acc.png\n",
      "[FIG] bilstm+attention_lstm_stage1_loss.png\n",
      "[FIG] bilstm+attention_lstm_stage2_acc.png\n",
      "[FIG] bilstm+attention_lstm_stage2_loss.png\n",
      "[FIG] bilstm+attention_lstm_stage3_acc.png\n",
      "[FIG] bilstm+attention_lstm_stage3_loss.png\n",
      "[FIG] textcnn_twitter-se_cnn_stage1_acc.png\n",
      "[FIG] textcnn_twitter-se_cnn_stage1_loss.png\n",
      "[FIG] textcnn_twitter-se_cnn_stage2_acc.png\n",
      "[FIG] textcnn_twitter-se_cnn_stage2_loss.png\n",
      "[FIG] textcnn_twitter-se_cnn_stage3_acc.png\n",
      "[FIG] textcnn_twitter-se_cnn_stage3_loss.png\n"
     ]
    }
   ],
   "source": [
    "hist_lstm = {\n",
    "    \"LSTM stage1\": locals().get(\"history_lstm_1\", None),\n",
    "    \"LSTM stage2\": locals().get(\"history_lstm_2\", None),\n",
    "    \"LSTM stage3\": locals().get(\"history_lstm_3\", None),\n",
    "}\n",
    "plot_training_curves(hist_lstm, \"BiLSTM+Attention\")\n",
    "\n",
    "hist_cnn = {\n",
    "    \"CNN stage1\": locals().get(\"history_stage1\", None),\n",
    "    \"CNN stage2\": locals().get(\"history_stage2\", None),\n",
    "    \"CNN stage3\": locals().get(\"history_stage3\", None),\n",
    "}\n",
    "plot_training_curves(hist_cnn, \"TextCNN Twitter-SE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0030bc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FIG] roberta_fe_test_umap.png\n"
     ]
    }
   ],
   "source": [
    "if RUN_ROBERTA_FEATURES and Xte_emb is not None:\n",
    "    try:\n",
    "        plot_umap(Xte_emb, y_test.values, \"UMAP of RoBERTa embeddings (test)\", \"roberta_fe_test\")\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] UMAP omitted:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9e6dfdb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[FINISHED] 🚀\n",
      "Artifacts saved in: /mnt/i/My Drive/Maestría En Ciencia de Datos/Tercer Trimestre/NLP/FinalProject-WorldCup-TweetClassification/fifa-wc-tweets-sentiment-classifier/SCRITPS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Figures:  /mnt/i/My Drive/Maestría En Ciencia de Datos/Tercer Trimestre/NLP/FinalProject-WorldCup-TweetClassification/fifa-wc-tweets-sentiment-classifier/SCRITPS/artifacts/figures\n",
      " - Tables:   /mnt/i/My Drive/Maestría En Ciencia de Datos/Tercer Trimestre/NLP/FinalProject-WorldCup-TweetClassification/fifa-wc-tweets-sentiment-classifier/SCRITPS/artifacts/tables\n",
      " - Logs:     /mnt/i/My Drive/Maestría En Ciencia de Datos/Tercer Trimestre/NLP/FinalProject-WorldCup-TweetClassification/fifa-wc-tweets-sentiment-classifier/SCRITPS/artifacts/logs\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[FINISHED] 🚀\")\n",
    "print(f\"Artifacts saved in: {OUTDIR.resolve()}\")\n",
    "print(f\" - Figures:  {FIGDIR.resolve()}\")\n",
    "print(f\" - Tables:   {TABDIR.resolve()}\")\n",
    "print(f\" - Logs:     {LOGDIR.resolve()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FIFA-WC-sentiment-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
